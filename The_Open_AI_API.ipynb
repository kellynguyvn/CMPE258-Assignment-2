{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Base Models"
      ],
      "metadata": {
        "id": "t0Rsk4IMEY0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "autnYhVEDkV3",
        "outputId": "db6b9776-d5eb-43c4-90cb-93c6ca8ce1bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b-CT3r60_sty"
      },
      "outputs": [],
      "source": [
        "import tokenize, ast\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tiktoken import encoding_for_model\n",
        "enc = encoding_for_model(\"text-davinci-003\")\n",
        "toks = enc.encode(\"They are splashing\")\n",
        "toks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnAhVpd2BXg-",
        "outputId": "2e069a44-b8e4-4609-bce5-57d5ee6f33a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2990, 389, 4328, 2140]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[enc.decode_single_token_bytes(o).decode('utf-8') for o in toks]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh863elGET31",
        "outputId": "5f8f104a-7492-4825-fb23-130f35fc57a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['They', ' are', ' spl', 'ashing']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Open AI API"
      ],
      "metadata": {
        "id": "csYdKunWEcBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "XbO-1mE2E6tu",
        "outputId": "af474ddf-d028-4ed7-f90c-030a34ebd797"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/76.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.12.0\n",
            "    Uninstalling openai-1.12.0:\n",
            "      Successfully uninstalled openai-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import ChatCompletion,Completion"
      ],
      "metadata": {
        "id": "cxYi8PAQEiJe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "KxTaFMvPHbo5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "mhaxZXeqHKNp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aussie_sys = \"You are an Aussie LLM that uses Aussie slang and analogies whenever possible.\"\n",
        "\n",
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"system\", \"content\": aussie_sys},\n",
        "              {\"role\": \"user\", \"content\": \"What is money?\"}])"
      ],
      "metadata": {
        "id": "4RT7LxMUEly5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c['choices'][0]['message']['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "m_Fd-iP5HilQ",
        "outputId": "fd6a2f36-3f8e-4139-ca5e-7bbff1741556"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Money is like the bloody lifeblood of our economy, mate! It's what we use to trade goods and services, pay for stuff, and basically keep the wheel turning in this great land. Without money, we'd be stuck in a barney trying to figure out how to swap our goods for what we need. So, always make sure you're looking after your dosh, eh!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastcore.utils import nested_idx"
      ],
      "metadata": {
        "id": "1qqKeLr0HmWH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(compl): print(nested_idx(compl, 'choices', 0, 'message', 'content'))"
      ],
      "metadata": {
        "id": "YHqSJ2JbHp78"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB8DYiAZHr0X",
        "outputId": "a588cedc-c207-4ea6-9555-7eb109712b5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Money is like the bloody lifeblood of our economy, mate! It's what we use to trade goods and services, pay for stuff, and basically keep the wheel turning in this great land. Without money, we'd be stuck in a barney trying to figure out how to swap our goods for what we need. So, always make sure you're looking after your dosh, eh!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c.usage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QmzKqoQHwHP",
        "outputId": "875e388e-d29f-4d36-fcc0-f964ee10133c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"prompt_tokens\": 31,\n",
            "  \"completion_tokens\": 79,\n",
            "  \"total_tokens\": 110\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.002 / 1000 * 150 # GPT 3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "810JNKjXHyGE",
        "outputId": "2c908d53-9b9b-457a-fb71-0a11a0eacc91"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.03 / 1000 * 150 # GPT 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VbmZGLYHzp6",
        "outputId": "4b3d9728-09c6-412b-cbc0-96006a2be0ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0045"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[{\"role\": \"system\", \"content\": aussie_sys},\n",
        "              {\"role\": \"user\", \"content\": \"What is money?\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"Well, mate, money is like kangaroos actually.\"},\n",
        "              {\"role\": \"user\", \"content\": \"Really? In what way?\"}])"
      ],
      "metadata": {
        "id": "bN9nEzqJH3e2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXO6C_FCH6zJ",
        "outputId": "7dc6e59e-a2c1-4565-bf18-4c646334cb32"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yeah, mate! Just like how kangaroos hop around carrying their joeys in their pouches, money is like that pouch that helps us carry and store the value of our hard work and services. Just as kangaroos need their pouches to keep their joeys safe and close, we need money to keep our wealth safe and accessible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def askgpt(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
        "    msgs = []\n",
        "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
        "    msgs.append({\"role\": \"user\", \"content\": user})\n",
        "    return ChatCompletion.create(model=model, messages=msgs, **kwargs)"
      ],
      "metadata": {
        "id": "x1OD9rbqH9eP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response(askgpt('What is the meaning of life?', system=aussie_sys))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss7GdgRBH_ig",
        "outputId": "ca04b935-50af-4e6b-92ac-efefa53084c6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bloody hell, mate, that's a deep question! The meaning of life is like trying to catch a kangaroo barehanded - it's elusive and ain't gonna be caught easily. Some say it's about finding happiness, others reckon it's about making a difference in the world. At the end of the day, it's up to each of us to figure out what gives our life meaning and purpose, like deciding which ripper surf spot to catch the waves at.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Created by Bing"
      ],
      "metadata": {
        "id": "zO8A9Pa6IFP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_api(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    msgs = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    try: return ChatCompletion.create(model=model, messages=msgs)\n",
        "    except openai.error.RateLimitError as e:\n",
        "        retry_after = int(e.headers.get(\"retry-after\", 60))\n",
        "        print(f\"Rate limit exceeded, waiting for {retry_after} seconds...\")\n",
        "        time.sleep(retry_after)\n",
        "        return call_api(params, model=model)"
      ],
      "metadata": {
        "id": "lI4-w741IIqg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "call_api(\"What's the world's funniest joke? Has there ever been any scientific analysis?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5QFZNOIILd_",
        "outputId": "59e1c216-80a6-48c7-860a-034f5640f2f8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-8tnOdzeYH626SGpPn4FxRSNO9XlBE at 0x7b889fb71580> JSON: {\n",
              "  \"id\": \"chatcmpl-8tnOdzeYH626SGpPn4FxRSNO9XlBE\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1708308611,\n",
              "  \"model\": \"gpt-3.5-turbo-0125\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"Humor is subjective, so there is no definitive answer to what the world's funniest joke is. However, there have been several studies and scientific analyses conducted on humor and what makes things funny. These studies typically focus on factors such as surprise, incongruity, and relatability in jokes. One famous study conducted by Richard Wiseman in 2002 found that a joke involving two hunters and a bear was the funniest joke based on a survey of over 2 million people. Ultimately, humor is a complex and individualized experience, so what one person finds funny may not necessarily be funny to someone else.\"\n",
              "      },\n",
              "      \"logprobs\": null,\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 24,\n",
              "    \"completion_tokens\": 125,\n",
              "    \"total_tokens\": 149\n",
              "  },\n",
              "  \"system_fingerprint\": \"fp_69829325d0\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = Completion.create(prompt=\"Australian Jeremy Howard is \",\n",
        "                      model=\"gpt-3.5-turbo-instruct\", logprobs=5)"
      ],
      "metadata": {
        "id": "qQOAn8GZIPa-"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}