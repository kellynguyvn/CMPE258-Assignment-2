{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install openai==0.28\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "OJPCWs9fJR3D",
        "outputId": "da7adcb0-fa1f-48b8-df6d-a5e155309339"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.12.0\n",
            "    Uninstalling openai-1.12.0:\n",
            "      Successfully uninstalled openai-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create our own Code Interpreter"
      ],
      "metadata": {
        "id": "tkfrukSQJEjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zVX9zNH-I8B5"
      },
      "outputs": [],
      "source": [
        "from pydantic import create_model\n",
        "import inspect, json\n",
        "from inspect import Parameter\n",
        "import openai\n",
        "from openai import ChatCompletion,Completion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sums(a:int, b:int=1):\n",
        "    \"Adds a + b\"\n",
        "    return a + b"
      ],
      "metadata": {
        "id": "1Ad1lSVMJDkR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def schema(f):\n",
        "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
        "          for n,o in inspect.signature(f).parameters.items()}\n",
        "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
        "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
      ],
      "metadata": {
        "id": "YBA9KEnmJLy9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema(sums)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QZE1-jNJOEz",
        "outputId": "e98c5996-342c-4af3-9c80-e3807d5f8f8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'sums',\n",
              " 'description': 'Adds a + b',\n",
              " 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
              "   'b': {'default': 1, 'title': 'B', 'type': 'integer'}},\n",
              "  'required': ['a'],\n",
              "  'title': 'Input for `sums`',\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def askgpt(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
        "    msgs = []\n",
        "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
        "    msgs.append({\"role\": \"user\", \"content\": user})\n",
        "    return ChatCompletion.create(model=model, messages=msgs, **kwargs)"
      ],
      "metadata": {
        "id": "Auf8F_jXJnVn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = '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'"
      ],
      "metadata": {
        "id": "4OxlwKEzJ9wj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = askgpt(\"Use the `sum` function to solve this: What is 6+3?\",\n",
        "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
        "           functions=[schema(sums)])"
      ],
      "metadata": {
        "id": "llQy7gqIJQD3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = c.choices[0].message\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kie04bxGKAJP",
        "outputId": "86a9ab9d-9c94-4e8a-de4b-945a15a49ace"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x7d62d1172480> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": null,\n",
              "  \"function_call\": {\n",
              "    \"name\": \"sums\",\n",
              "    \"arguments\": \"{\\\"a\\\":6,\\\"b\\\":3}\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = m.function_call.arguments\n",
        "print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWZ0XgR5KCFs",
        "outputId": "78679cb1-72a4-4dd6-e195-f89b8291c78e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"a\":6,\"b\":3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "funcs_ok = {'sums', 'python'}"
      ],
      "metadata": {
        "id": "E3Kech1YKGsv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_func(c):\n",
        "    fc = c.choices[0].message.function_call\n",
        "    if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
        "    f = globals()[fc.name]\n",
        "    return f(**json.loads(fc.arguments))"
      ],
      "metadata": {
        "id": "uYv6GlZCKIhp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "call_func(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qos_2QUXKKSx",
        "outputId": "764c79c5-bbec-486d-e19c-9817fdd2d667"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run(code):\n",
        "    tree = ast.parse(code)\n",
        "    last_node = tree.body[-1] if tree.body else None\n",
        "\n",
        "    # If the last node is an expression, modify the AST to capture the result\n",
        "    if isinstance(last_node, ast.Expr):\n",
        "        tgts = [ast.Name(id='_result', ctx=ast.Store())]\n",
        "        assign = ast.Assign(targets=tgts, value=last_node.value)\n",
        "        tree.body[-1] = ast.fix_missing_locations(assign)\n",
        "\n",
        "    ns = {}\n",
        "    exec(compile(tree, filename='<ast>', mode='exec'), ns)\n",
        "    return ns.get('_result', None)"
      ],
      "metadata": {
        "id": "_ZFc1hlCKMIt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast"
      ],
      "metadata": {
        "id": "W7YdyzB2KX5a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run(\"\"\"\n",
        "a=1\n",
        "b=2\n",
        "a+b\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gicJ6Z9xKONp",
        "outputId": "6bf67380-972f-44da-d8f3-14b3280afb67"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def python(code:str):\n",
        "    \"Return result of executing `code` using python. If execution not permitted, returns `#FAIL#`\"\n",
        "    go = input(f'Proceed with execution?\\n```\\n{code}\\n```\\n')\n",
        "    if go.lower()!='y': return '#FAIL#'\n",
        "    return run(code)"
      ],
      "metadata": {
        "id": "QyVLRTUkKbMg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = askgpt(\"What is 12 factorial?\",\n",
        "           system = \"Use python for any required computations.\",\n",
        "           functions=[schema(python)])"
      ],
      "metadata": {
        "id": "r-pMQBPSKcwu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "call_func(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i0AU7m6Kelm",
        "outputId": "49b77d64-7cdd-4ce3-c4b6-a1323d989126"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proceed with execution?\n",
            "```\n",
            "import math\n",
            "math.factorial(12)\n",
            "```\n",
            "y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "479001600"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    functions=[schema(python)],\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What is 12 factorial?\"},\n",
        "              {\"role\": \"function\", \"name\": \"python\", \"content\": \"479001600\"}])"
      ],
      "metadata": {
        "id": "CxBgSxQlKjJ9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastcore.utils import nested_idx"
      ],
      "metadata": {
        "id": "JaStv6BBKz8X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(compl): print(nested_idx(compl, 'choices', 0, 'message', 'content'))"
      ],
      "metadata": {
        "id": "mtK2oTMcKsh8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha-uIYASKll5",
        "outputId": "b75f4f87-b379-4726-c2b5-3fb9a48ad6cc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The factorial of 12 is 479001600.\n"
          ]
        }
      ]
    }
  ]
}